{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ace824cc-732d-4f08-b351-7d4389ce1aa6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31cef3ea-bd1c-4afc-bdbc-1963696d9c7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 04L - Deploy a DAB to Multiple Environments\n",
    "\n",
    "### Estimated Duration: 15-20 minutes\n",
    "\n",
    "In this lab, you will:\n",
    "\n",
    "1. Modify the variables in the **databricks.yml** file to reference the correct resources and variables (dev and prod).\n",
    "\n",
    "2. Deploy a project to the **development** and **production** environments with different configurations for each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f696b038-0ebf-46d5-beaf-8c0349b772aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## REQUIRED - SELECT CLASSIC COMPUTE\n",
    "\n",
    "Before executing cells in this notebook, please select your classic compute cluster in the lab. Be aware that **Serverless** is enabled by default.\n",
    "\n",
    "Follow these steps to select the classic compute cluster:\n",
    "\n",
    "1. Navigate to the top-right of this notebook and click the drop-down menu to select your cluster. By default, the notebook will use **Serverless**.\n",
    "\n",
    "1. If your cluster is available, select it and continue to the next cell. If the cluster is not shown:\n",
    "\n",
    "  - In the drop-down, select **More**.\n",
    "\n",
    "  - In the **Attach to an existing compute resource** pop-up, select the first drop-down. You will see a unique cluster name in that drop-down. Please select that cluster.\n",
    "\n",
    "**NOTE:** If your cluster has terminated, you might need to restart it in order to select it. To do this:\n",
    "\n",
    "1. Right-click on **Compute** in the left navigation pane and select *Open in new tab*.\n",
    "\n",
    "1. Find the triangle icon to the right of your compute cluster name and click it.\n",
    "\n",
    "1. Wait a few minutes for the cluster to start.\n",
    "\n",
    "1. Once the cluster is running, complete the steps above to select your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e993b63a-80ce-4caa-b4a9-69377e143e98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## A. Classroom Setup\n",
    "\n",
    "Run the following cell to configure your working environment for this course.\n",
    "\n",
    "**NOTE:** The `DA` object is only used in Databricks Academy courses and is not available outside of these courses. It will dynamically reference the information needed to run the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe809286-4ee2-4579-b677-4a7bf7e87818",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../Includes/Classroom-Setup-04L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "783b433f-1ce9-489f-8db8-85d6af34c53c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## IMPORTANT LAB INFORMATION\n",
    "\n",
    "Recall that your credentials are stored in a file when running [0 - REQUIRED - Course Setup and Authentication]($../0 - REQUIRED - Course Setup and Authentication).\n",
    "\n",
    "If you end your lab or your lab session times out, your environment will be reset.\n",
    "\n",
    "If you encounter an error regarding unavailable catalogs or if your Databricks CLI is not authenticated, you will need to rerun the [0 - REQUIRED - Course Setup and Authentication]($../0 - REQUIRED - Course Setup and Authentication) notebook to recreate the catalogs and your Databricks CLI credentials.\n",
    "\n",
    "**Use classic compute to use the CLI through a notebook.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a775a590-d65c-4167-add2-72a7071cb787",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## SCENARIO\n",
    "\n",
    "You are in charge of deploying Databricks projects in your organization using Databricks Asset Bundles. So far, you've configured the project to deploy to the **development** environment (**02L - Deploy a Simple DAB**). Your next task is to modify the **databricks.yml** file to deploy the project into the development and production environments with different configurations. You will accomplish this with variable substitution.\n",
    "\n",
    "#### Development configuration target requirements:\n",
    "- Use the development data in your **username_1_dev** catalog\n",
    "\n",
    "#### Production configuration target requirements:\n",
    "- Use the development data in your **username_3_stage** catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "352e7f67-fe91-4b20-8127-64e8b6b545c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## B. Preview the Development and Production Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "00cb699b-1df9-416c-b54c-c4292e80cd9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Preview the **nyctaxi_raw** development data within your **username_1_dev** catalog. Notice that the dev data contains 100 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f521c79-3875-4d47-af8e-2176ca2d0a76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'''\n",
    "          SELECT * \n",
    "          FROM {DA.catalog_dev}.default.nyctaxi_raw\n",
    "          ''').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d97b902d-fc17-47a3-9831-52ad968822d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. View the tables in your **username_1_dev** catalog. Notice that the **nyctaxi_bronze** and **nyctaxi_silver** tables do not exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93b64067-5fb2-4e5c-abcc-55669e812b7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'SHOW TABLES IN {DA.catalog_dev}.default').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a43e02d1-b659-4787-9d6a-10e633f98e27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Preview the **nyctaxi_raw** production data within your **username_3_prod** catalog. Notice that the production data contains about 22,000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64137bc0-a214-4189-bc33-9bcc021fb3c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'''\n",
    "          SELECT count(*) AS TotalRows \n",
    "          FROM {DA.catalog_prod}.default.nyctaxi_raw\n",
    "          ''').display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74beb3ab-1655-4498-9595-4620ac5f93f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'''\n",
    "          SELECT * \n",
    "          FROM {DA.catalog_prod}.default.nyctaxi_raw\n",
    "          ''').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4ed27f7-adec-4007-bf8f-05756ff7c317",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. View the tables in your **username_3_prod** catalog. Notice that the **nyctaxi_bronze** and **nyctaxi_silver** tables do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "229ef3eb-f34f-4578-8e34-c7fa7b75010f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'SHOW TABLES IN {DA.catalog_prod}.default').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69074127-82a7-4f57-a4f4-b36624816eaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## C. TO DO: STEPS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f300521-af64-4a3e-84fe-84946554d64d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Run the cell below to obtain your lab user name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d53b1d65-8665-4149-9519-b8d3e1e21be0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(DA.catalog_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5c969bd-898a-4e7e-8f48-51b30f7cf8df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. In a new tab, open the **./resources/lab04_nyc.job.yml** file. Explore the file and complete the following:\n",
    "\n",
    "   a. Name the actual job **lab04_dab_`${workspace.current_user.userName}`**. This will dynamically add your user name to the end of the job.\n",
    "\n",
    "   b. Under **parameters** add the bundle target variable as the default value of **display_target**\n",
    "    - **HINT:** [Variable substitutions](https://docs.databricks.com/aws/en/dev-tools/bundles/variables)\n",
    "\n",
    "\n",
    "<br></br>\n",
    "**Solution Resources File**\n",
    "```YAML\n",
    "resources:\n",
    "  jobs:\n",
    "    lab04_dab:\n",
    "      name: lab04_dab_${workspace.current_user.userName}  # <----- lab04_dab_ + Append your user name variable value to the end of the job name\n",
    "      tasks:\n",
    "        - task_key: create_nyc_tables\n",
    "          notebook_task:\n",
    "            notebook_path: ../src/our_project_code.sql\n",
    "            source: WORKSPACE\n",
    "      parameters:\n",
    "        - name: target\n",
    "          default: ${bundle.target}       # <---- Add the bundle.target variable here as a job value\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1f76107-1d99-4061-9daf-2a6ad31ada53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. In the new tab, open the **databricks.yml** file and explore the bundle configuration. Notice the following:\n",
    "\n",
    "  - The bundle name is **demo04_lab_bundle**.\n",
    "\n",
    "  - The **include** mapping is empty.\n",
    "\n",
    "  - The **variables** mapping contains a variety of variables. Explore the variables.\n",
    "\n",
    "  - The **target** mapping contains a **dev** and **prod** target environment.\n",
    "\n",
    "  Leave the **databricks.yml** file open.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5015f69-96ab-4b5d-97ab-54c044fa0253",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. In the **databricks.yml**, complete the following:\n",
    "\n",
    "   a. In **includes**, add the **./resources/lab04_nyc.job.yml** file.\n",
    "      - **HINT:** [include mapping](https://docs.databricks.com/aws/en/dev-tools/bundles/settings#include)\n",
    "\n",
    "   b. In **variables**, add your username to the variable `user_name` (your lab username can be found in step 1 of this section).\n",
    "      - The `user_name` variable populates the `catalog_dev` and `catalog_prod` variables dynamically.\n",
    "\n",
    "   c. Under **targets**, complete the following to modify the catalog for the **dev** and **prod** targets by adding a job parameter specific to each target:\n",
    "\n",
    "   - For the **dev** environment, create a job parameter named **catalog_name** that uses the `var.catalog_dev` value.\n",
    "\n",
    "   - For the **prod** environment, create a job parameter named **catalog_name** that uses the `var.catalog_prod` value.\n",
    "\n",
    "   This is a great way to change the deployment based on the target environment. This example keeps it simple by adding basic job parameters, but you can modify a variety of configuration values using this method.\n",
    "\n",
    "   **NOTE:** You can add or modify the configuration of your resources within the **targets** configuration based on the environment requirements. In this example, we are adding a specific job parameter for dev and prod to our job defined in the **./resources/lab04_nyc.job.yml** file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f6d474f-3498-4eaf-a6bb-64d6e2a10c0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### C1. Deploy to Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b3a3508-4972-4ade-95d6-c189602ade21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Run the Databricks CLI command below to confirm the Databricks CLI is authenticated.\n",
    "\n",
    "<br></br>\n",
    "##### DATABRICKS CLI ERROR TROUBLESHOOTING:\n",
    "  - If you encounter an Databricks CLI authentication error, it means you haven't created the PAT token specified in notebook **0 - REQUIRED - Course Setup and Authentication**. You will need to set up Databricks CLI authentication as shown in that notebook.\n",
    "\n",
    "  - If you encounter the error below, it means your `databricks.yml` file is invalid due to a modification. Even for non-DAB CLI commands, the `databricks.yml` file is still required, as it may contain important authentication details, such as the host and profile, which are utilized by the CLI commands.\n",
    "\n",
    "![CLI Invalid YAML](../Includes/images/databricks_cli_error_invalid_yaml.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a10bd395-01c0-43f0-b92e-1a1234190d16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "databricks catalogs list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1aa2d8fe-c6be-4b87-8d53-05101395b59b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Check the version of the Databricks CLI. Confirm the version is **v0.257.0**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "997d92bb-3e91-456c-b3a0-2609898868e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "databricks -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95667dde-5f4f-46a3-98f7-07044b8f6741",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Validate your **databricks.yml** bundle configuration file using the Databricks CLI. Run the cell and confirm the validation was successful. If there is an error fix the error. \n",
    "\n",
    "    **HINT:** You can refer to the documentation for the [bundle command group](https://docs.databricks.com/en/dev-tools/cli/bundle-commands.html) for help with validating, deploying, running, and destroying a bundle.\n",
    "\n",
    "\n",
    "    **NOTE:** For an example solution you can view the **databricks_solution.yml** file within the **solutions** folder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7989bfb-7255-4c6d-92c9-4f10f8221cec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "databricks bundle validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c6c9cf8-b77b-479e-b28a-34b7144582db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4. Deploy the bundle to the development environment using the Databricks CLI.\n",
    "\n",
    "    After the cell completes:\n",
    "    - Manually check to see if the job was created successfully. The job name will be **[dev user_name] lab04_job_username**.\n",
    "    - Check the **job parameters** and confirm it's using your **username_1_dev** catalog and that the **target** is *dev*.\n",
    "\n",
    "    **NOTE:** This will take about a minute to complete.\n",
    "\n",
    "    **HINT:** You can refer to the documentation for the [bundle command group](https://docs.databricks.com/en/dev-tools/cli/bundle-commands.html) for help with validating, deploying, running, and destroying a bundle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18ba954d-8478-4964-9e29-e1f9250293c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "<FILL-IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "197083b1-9f9a-45a9-8732-cedb3e792540",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "%sh\n",
    "databricks bundle deploy -t dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a1115fc5-e3e6-42b6-927a-60a3f7889b1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5. Run the bundle using the target development environment using the Databricks CLI. \n",
    "\n",
    "    **NOTE:** This will take about a 1-2 minutes to complete.\n",
    "\n",
    "    **HINT:** You can refer to the documentation for the [bundle command group](https://docs.databricks.com/en/dev-tools/cli/bundle-commands.html) for help with validating, deploying, running, and destroying a bundle.\n",
    "\n",
    "\n",
    "    **HINT:** Remember to use the key name from the resources mapping in the databricks.yml file(your name will differ):\n",
    "```\n",
    "...\n",
    "resources:\n",
    "  jobs:\n",
    "    lab04_dab:    # <--- The job key name here\n",
    "      name: lab04_dab_${var.user_name}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2334bde-7aa2-4e32-9bf2-28fba70e9dfa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "<FILL-IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "992c6b17-f416-4aed-b0a1-2ed94900e4d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "%sh\n",
    "databricks bundle run -t dev lab04_dab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a90f10d-6552-4cf7-94e3-eb84e3159958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "6. After the job successfully completes, run the following cells to confirm both tables **nyctaxi_bronze** and **nyctaxi_silver**  were created in the **username_1_dev** catalog, and the **nyctaxi_bronze** table contains 100 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83e7fe0b-4dd4-4232-a05a-8446b39529fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'SHOW TABLES IN {DA.catalog_dev}.default').display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3d31fbd-e233-4c40-aee9-931ea7b29d57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "check_nyctaxi_bronze_table(user_catalog = DA.catalog_dev, total_count=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84e94272-f013-4f9a-8304-be8439e5a958",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### C2. Deploy to Production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5381bf92-fb7a-4182-8170-df713c785f41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Deploy the bundle to the production environment using the Databricks CLI. This will take about a minute to complete.\n",
    "\n",
    "    After the cell completes:\n",
    "    - Manually check to see if the job was created successfully. The job name will be **lab04_job_username**.\n",
    "    - Check the **job parameters** and confirm it's using your **username_3_prod** catalog and that the **target** is *prod*.\n",
    "\n",
    "**HINT:** You can refer to the documentation for the [bundle command group](https://docs.databricks.com/en/dev-tools/cli/bundle-commands.html) for help with validating, deploying, running, and destroying a bundle.\n",
    "\n",
    "**NOTE:** Typically when running in production you will want to run the job using a service principal. For more information, check out the [Set a bundle run identity](https://docs.databricks.com/aws/en/dev-tools/bundles/run-as). For demonstration purposes, we are simply running the production job as the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "979ba540-cbca-4cf7-9cdf-54d42e3c6d93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "<FILL-IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae2b4dc6-a76b-445a-998a-9130f5433e64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "%sh\n",
    "databricks bundle deploy -t prod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd6aa02f-f728-40a2-87b1-e235612b10d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Run the bundle using the target production environment using the Databricks CLI. \n",
    "\n",
    "    **NOTE:** This will take about a 1-2 minutes to complete.\n",
    "\n",
    "    **HINT:** You can refer to the documentation for the [bundle command group](https://docs.databricks.com/en/dev-tools/cli/bundle-commands.html) for help with validating, deploying, running, and destroying a bundle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8de14478-7fca-428c-8f24-0868cb7e2b3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "<FILL-IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcd9728b-401a-4f31-8e69-7e9d72aaf7e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%skip\n",
    "%sh\n",
    "databricks bundle run -t prod lab04_dab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4428e0fa-0436-44db-8c17-464e1838bc79",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. After the job successfully completes, run the following cells to confirm both tables **nyctaxi_bronze** and **nyctaxi_silver**  were created in the **username_3_prod** catalog, and the **nyctaxi_bronze** table contains 21,932 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0687d69-6b8c-4774-a54a-d404d5fd62fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'SHOW TABLES IN {DA.catalog_prod}.default').display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "395e788f-7c24-4f2e-a063-cb79c6d752f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "check_nyctaxi_bronze_table(user_catalog = DA.catalog_prod, total_count=21932)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fc6967a-185c-4c8b-a282-661145f62d3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### BONUS\n",
    "This was a simple example of deploying a DAB to multiple environments.\n",
    "\n",
    "- There are a variety of ways to set a variable's value. In this lab, we set values within the **databricks.yml** configuration file. You can also set variable values within the Databricks CLI. For more information, view the [Set a variableâ€™s value](https://docs.databricks.com/en/dev-tools/bundles/variables.html#set-a-variables-value) documentation.\n",
    "\n",
    "- For additional information on overriding configuration values for environments, view the [Override cluster settings in Databricks Asset Bundles](https://docs.databricks.com/aws/en/dev-tools/bundles/cluster-override) documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "101284c1-0858-4e62-8faf-3abc85e043b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Lab - Deploy a DAB to Multiple Environments",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
