{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71f7797d-0a2d-45ff-b8fa-784f3a33dd96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c13a863e-2f04-4de3-b763-b92be113cc45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Incremental Processing with Spark Structured Streaming\n",
    "This module is part of the Data Engineer Learning Path by Databricks Academy. \n",
    "\n",
    "#### Lessons\n",
    "Lecture: Streaming Data Concepts (slides available in .pdf)<br>\n",
    "Lecture: Introduction to Structured Streaming (slides available in .pdf) <br>\n",
    "[SDLT 1.1 - Reading from a Streaming Query]($./SDLT 1.1 - Reading from a Streaming Query) <br>\n",
    "[SDLT 1.2L - Streaming Query Lab]($./SDLT 1.2L - Streaming Query Lab) <br>\n",
    "Lecture: Aggregations, Time Windows, Watermarks (slides available in .pdf) <br>\n",
    "[SDLT 1.3L - Stream Aggregations Lab]($./SDLT 1.3L - Stream Aggregations Lab) <br>\n",
    "[SDLT 1.4 - Windowed Aggregation with Watermark]($./SDLT 1.4 - Windowed Aggregation with Watermark) <br> \n",
    "[SDLT 1.5 - Stream-Stream Joins (Optional)]($./SDLT 1.5 - Optional - Stream-Stream Joins) <br> \n",
    "\n",
    "---\n",
    "\n",
    "#### Prerequisites\n",
    "* Ability to perform basic code development tasks using the Databricks Data Engineering & Data Science workspace (create clusters, run code in notebooks, use basic notebook operations, import repos from git, etc)\n",
    "* Intermediate programming experience with PySpark\n",
    "  * Extract data from a variety of file formats and data sources\n",
    "  * Apply a number of common transformations to clean data\n",
    "  * Reshape and manipulate complex data using advanced built-in functions\n",
    "* Intermediate programming experience with Delta Lake (create tables, perform complete and incremental updates, compact files, restore previous versions etc.)\n",
    "\n",
    "---\n",
    "\n",
    "#### Technical Considerations\n",
    "* This course runs on **`17.3.x-scala2.13`**.\n",
    "* This course cannot be delivered on Databricks Community Edition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f352c32-8df6-4245-9f7a-ca30a63030af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "SDLT 1.0 - Module Introduction",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
