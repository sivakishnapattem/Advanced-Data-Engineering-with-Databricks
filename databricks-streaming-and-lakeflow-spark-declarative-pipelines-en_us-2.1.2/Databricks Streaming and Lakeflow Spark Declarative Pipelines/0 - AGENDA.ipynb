{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14722e68-d2e9-4b65-9963-4901b97cb2bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img\n",
    "    src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\"\n",
    "    alt=\"Databricks Learning\"\n",
    "  >\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "852b6e4e-77ec-4293-9a70-121bc4dded2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Databricks Streaming and Lakeflow Spark Declarative Pipelines (Formerly DLT)\n",
    "\n",
    "This course provides a comprehensive understanding of Spark Structured Streaming and Delta Lake, including computation models, configuration for streaming reads, and maintaining data quality in a streaming environment.\n",
    "\n",
    "---\n",
    "\n",
    "### Prerequisites\n",
    "You should meet the following prerequisites before starting this course:\n",
    "\n",
    "- Ability to perform basic code development tasks using the Databricks Data Engineering and Data Science workspace (`create clusters`, `run code in notebooks`, `use basic notebook operations`, `import repos from git`, etc.)\n",
    "- Intermediate programming experience with PySpark\n",
    "- Extract data from a variety of file formats and data sources\n",
    "- Apply common transformations to clean data\n",
    "- Reshape and manipulate complex data using advanced built-in functions\n",
    "- Intermediate programming experience with Delta Lake (`create tables`, `perform complete and incremental updates`, `compact files`, `restore previous versions`, etc.)\n",
    "\n",
    "\n",
    "Beginner experience configuring and scheduling data pipelines using the Delta Live Tables UI\n",
    "\n",
    "- Beginner experience defining Lakeflow Declarative pipelines using PySpark\n",
    "- Ingest and process data using Auto Loader and PySpark syntax\n",
    "- Process Change Data Capture feeds with `APPLY CHANGES INTO` syntax\n",
    "- Review pipeline event logs and results to troubleshoot Declarative Pipeline syntax\n",
    "\n",
    "---\n",
    "\n",
    "### Course Agenda\n",
    "The following modules are part of the **Data Engineer Learning Path** by Databricks Academy.\n",
    "\n",
    "| # | Module Name |\n",
    "| --- | --- |\n",
    "| 1 | [Incremental Processing with Spark Structured Streaming]($./SDLT 1 - Incremental Processing with Spark Structured Streaming/SDLT 1.0 - Module Introduction) |\n",
    "| 2 | [Streaming ETL Patterns with Lakeflow Declarative Pipelines]($./SDLT 2 - Streaming ETL Patterns with Lakeflow Spark Declarative Pipelines/SDLT 2.0 - Module Introduction) |\n",
    "\n",
    "---\n",
    "\n",
    "### Requirements\n",
    "\n",
    "Please review the following requirements before starting the lesson:\n",
    "\n",
    "- Use Databricks Runtime version: **`17.3.x-scala2.13`** for running all demo and lab notebooks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fe77d1b-032a-43ed-9b97-6c6e1aeb6309",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "&copy; 2026 Databricks, Inc. All rights reserved. Apache, Apache Spark, Spark, the Spark Logo, Apache Iceberg, Iceberg, and the Apache Iceberg logo are trademarks of the <a href=\"https://www.apache.org/\" target=\"_blank\">Apache Software Foundation</a>.<br/><br/><a href=\"https://databricks.com/privacy-policy\" target=\"_blank\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\" target=\"_blank\">Terms of Use</a> | <a href=\"https://help.databricks.com/\" target=\"_blank\">Support</a>"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "0 - AGENDA",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
