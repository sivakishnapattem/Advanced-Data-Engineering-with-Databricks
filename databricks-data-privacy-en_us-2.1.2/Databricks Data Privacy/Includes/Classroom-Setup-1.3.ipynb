{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68783d06-a8de-446a-98af-4a041b39226d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Classroom-Setup-Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbae7451-8515-470a-b771-28d791ac1e27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@DBAcademyHelper.add_method\n",
    "def create_user_delete_requests_table(self, schema_name=\"pii_data\"):\n",
    "    '''\n",
    "    Create delte requests table.\n",
    "    '''\n",
    "    print(f\"Creating the user delete requests table within your Catalog's {schema_name} schema.\")\n",
    "        \n",
    "    r = spark.sql(f'DROP TABLE IF EXISTS {self.catalog_name}.{schema_name}.user_delete_requests')\n",
    "\n",
    "    r = spark.sql(f'''\n",
    "    CREATE TABLE {self.catalog_name}.{schema_name}.user_delete_requests (\n",
    "        mrn BIGINT,\n",
    "        request_date timestamp\n",
    "    )\n",
    "    ''')\n",
    "\n",
    "    r = spark.sql(f'''\n",
    "    INSERT INTO {self.catalog_name}.{schema_name}.user_delete_requests (\n",
    "        mrn, \n",
    "        request_date\n",
    "    )\n",
    "    VALUES\n",
    "    (46609218, current_timestamp()),\n",
    "    (10481208, current_timestamp()),\n",
    "    (51962029, current_timestamp()),\n",
    "    (36170414, current_timestamp()),\n",
    "    (57985430, current_timestamp()),\n",
    "    (92891095, current_timestamp()),\n",
    "    (77708899, current_timestamp()),\n",
    "    (84079469, current_timestamp()),\n",
    "    (80880484, current_timestamp()),\n",
    "    (12267606, current_timestamp()),\n",
    "    (16352917, current_timestamp()),\n",
    "    (39313172, current_timestamp()),\n",
    "    (55302643, current_timestamp()),\n",
    "    (60252784, current_timestamp()),\n",
    "    (39141616, current_timestamp()),\n",
    "    (48952287, current_timestamp()),\n",
    "    (27210934, current_timestamp()),\n",
    "    (97829250, current_timestamp()),\n",
    "    (72095631, current_timestamp()),\n",
    "    (56413066, current_timestamp())\n",
    "    ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "207ac592-e2fc-4611-9896-1ce0427b0e70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Set default schema to pii_data\n",
    "schema = spark.sql('USE SCHEMA pii_data')\n",
    "\n",
    "## Create volume in user's catalog within the pii_data schema named CDF demo\n",
    "spark.sql(f'CREATE VOLUME IF NOT EXISTS {DA.catalog_name}.pii_data.cdf_demo')\n",
    "\n",
    "\n",
    "##\n",
    "## Set DA paths\n",
    "##\n",
    "\n",
    "## Set path to working directory location to store stream data for CDC (ops -> volumes -> user volume)\n",
    "setattr(DA, 'paths.stream_source.cdf_demo', f'{DA.paths.working_dir}/cdf_demo/stream_source/cdc')\n",
    "\n",
    "## Create a cdf_demo/stream_source/cdc folder in the cdf_demo volume in the pii_data schema\n",
    "setattr(DA,'paths.cdc_stream',f'/Volumes/{DA.catalog_name}/pii_data/cdf_demo/stream_source/cdc')\n",
    "\n",
    "## Create a cdf_demo/_checkpoints folder in the cdf_demo volume in the pii_data schema\n",
    "setattr(DA,'paths.checkpoints',f'/Volumes/{DA.catalog_name}/pii_data/cdf_demo/_checkpoints')\n",
    "\n",
    "##\n",
    "## Delete any files in the locations path\n",
    "##\n",
    "print('\\n------- Resetting Files for the Start of the Demo -------\\n')\n",
    "DA.delete_source_files(source_files=DA.paths.stream_source.cdf_demo)\n",
    "DA.delete_source_files(source_files=DA.paths.cdc_stream)\n",
    "\n",
    "try:\n",
    "    dbutils.fs.rm(DA.paths.checkpoints, True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "##\n",
    "## Create directories\n",
    "## \n",
    "\n",
    "## Create a folder {DA.paths.working_dir}/cdf_demo/stream_source/cdc folder in the dbacademy.ops user's volume\n",
    "dbutils.fs.mkdirs(DA.paths.stream_source.cdf_demo)\n",
    "\n",
    "## Create a folder /Volumes/{DA.catalog_name}/pii_data/cdf_demo/stream_source/cdc within the pii_data schema\n",
    "dbutils.fs.mkdirs(DA.paths.cdc_stream)\n",
    "\n",
    "## Create a folder /Volumes/{DA.catalog_name}/pii_data/cdf_demo/_checkpoints within the pii_data schema\n",
    "dbutils.fs.mkdirs(f'{DA.paths.checkpoints}')\n",
    "\n",
    "\n",
    "## Load files to dbacademy-ops-uservolume-cdf_demo \n",
    "DA.load_cdc_json(target_path=DA.paths.stream_source.cdf_demo)\n",
    "\n",
    "\n",
    "## Drop table if exists\n",
    "print('\\nDrop the bronze_users table if it exists.')\n",
    "dropTable = spark.sql(f'DROP TABLE IF EXISTS {DA.catalog_name}.pii_data.bronze_users')\n",
    "\n",
    "print('\\nDrop the delete_requests table if it exists.')\n",
    "dropTable = spark.sql(f'DROP TABLE IF EXISTS {DA.catalog_name}.pii_data.delete_requests')\n",
    "\n",
    "# Create user delete requests for delete propagation section\n",
    "DA.create_user_delete_requests_table()\n",
    "\n",
    "## Display values for users\n",
    "DA.display_config_values([\n",
    "            ('Your Course Catalog Name', DA.catalog_name),\n",
    "            ('Your Schema Name', 'pii_data'),\n",
    "            ('Source Data Volume (DA.paths.cdc_stream)', DA.paths.cdc_stream),\n",
    "            ('Your Checkpoint Location (DA.paths.checkpoints)', DA.paths.checkpoints)\n",
    "        ])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Classroom-Setup-1.3",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
