{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ccbebbcc-c802-4d14-a0ad-474f6f02e90f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Classroom-Setup-Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f47e0742-0cc1-4dcf-96e6-5dc49246ebaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f'CREATE VOLUME IF NOT EXISTS {DA.catalog_name}.pii_data.pii')\n",
    "\n",
    "##\n",
    "## Set paths to user's catalog within the pii_data schema\n",
    "##\n",
    "\n",
    "## Set path to DA.paths.stream_source.user_reg to the user's pii_data schema's volume \n",
    "## (catalog -> pii_data)\n",
    "setattr(DA, 'paths.stream_source.user_reg', f'/Volumes/{DA.catalog_name}/pii_data/pii/stream_source/user_reg')\n",
    "dbutils.fs.mkdirs(DA.paths.stream_source.user_reg)\n",
    "\n",
    "\n",
    "## Set path to write location DA.paths.stream_source.dialy to the user's pii_data schema's volume \n",
    "## (catalog -> pii_data)\n",
    "setattr(DA, 'paths.stream_source.daily', f'/Volumes/{DA.catalog_name}/pii_data/pii/stream_source/daily')\n",
    "dbutils.fs.mkdirs(DA.paths.stream_source.daily)\n",
    "\n",
    "## Set path to working directory location \n",
    "## (ops -> volumes -> user volume)\n",
    "setattr(DA, 'paths.stream_source.daily_working_dir', f'{DA.paths.working_dir}/pii/stream_source/daily')\n",
    "dbutils.fs.mkdirs(DA.paths.stream_source.daily_working_dir)\n",
    "\n",
    "\n",
    "# ## Set path to read location\n",
    "# setattr(DA, 'paths.stream_source.bronze', '/Volumes/dbacademy_gym_data/v01/bronze')\n",
    "\n",
    "\n",
    "##\n",
    "## Delete all files/tables prior to the demonstration\n",
    "##\n",
    "spark.sql(f'DROP TABLE IF EXISTS {DA.catalog_name}.pii_data.date_lookup_raw')\n",
    "spark.sql(f'DROP TABLE IF EXISTS {DA.catalog_name}.pii_data.date_lookup_raw')\n",
    "\n",
    "print('\\n------- Resetting Files for the Demo -------\\n')\n",
    "DA.delete_source_files(source_files=DA.paths.stream_source.user_reg)\n",
    "DA.delete_source_files(source_files=DA.paths.stream_source.daily)\n",
    "DA.delete_source_files(source_files=DA.paths.stream_source.daily_working_dir)\n",
    "\n",
    "# Reads the bronze delta table as a spark dataframe from marketplace and creates JSON files in the labusers working dir (ops) with 4 partitions.\n",
    "DA.load_daily_json(source_dir='/Volumes/dbacademy_gym_data/v01/bronze', \n",
    "                   target_path=DA.paths.stream_source.daily_working_dir)\n",
    "\n",
    "\n",
    "## Load files into the users DA.paths.stream_source.user_reg volume\n",
    "DA.load(copy_from='/Volumes/dbacademy_gym_data/v01/user-reg', \n",
    "        copy_to=f'{DA.paths.stream_source.user_reg}', \n",
    "        n=5)\n",
    "\n",
    "# ## Load files into the users DA.paths.stream_source.user_reg volume\n",
    "DA.load(copy_from=DA.paths.stream_source.daily_working_dir, \n",
    "        copy_to=DA.paths.stream_source.daily, \n",
    "        n=2)\n",
    "\n",
    "\n",
    "## Set default schema to pii\n",
    "r = spark.sql(f'USE SCHEMA pii_data')\n",
    "\n",
    "## Create the date_lookup table in user's catalog pii_data schema by copying from marketplace\n",
    "spark.sql(f'''\n",
    "CREATE TABLE IF NOT EXISTS {DA.catalog_name}.pii_data.date_lookup_raw\n",
    "AS\n",
    "SELECT *\n",
    "FROM delta.`/Volumes/dbacademy_gym_data/v01/date-lookup`\n",
    "''')\n",
    "\n",
    "\n",
    "## Display user values\n",
    "DA.display_config_values([\n",
    "        ('Your Course Catalog Name',DA.catalog_name), \n",
    "        ('Your Schema','pii_data'),\n",
    "        ('User Reg Files (DA.paths.stream_source.user_reg)', DA.paths.stream_source.user_reg),\n",
    "        ('Daily Files (DA.paths.stream_source.daily)', DA.paths.stream_source.daily)\n",
    "      ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Classroom-Setup-1.2",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
